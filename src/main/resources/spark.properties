## sparkConf load file

# spark spark.sql.shuffle.partitions
spark.sql.shuffle.partitions=4

# spark serializer
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.classesToRegister=org.apache.hadoop.hbase.io.ImmutableBytesWritable,org.apache.hadoop.hbase.client.Result,org.apache.hadoop.hbase.client.Put
spark.hadoop.validateOutputSpecs=false

# solve Truncated the string representation of a plan since it was too large.
# (Error terminating during conversion String operation when DF field is too long)
spark.debug.maxToStringFields=1000
